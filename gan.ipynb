{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for cats generation\n",
    "\n",
    "\n",
    "<b>Author:</b> Przemyslaw Niedziela (przemyslaw.niedziela98@gmail.com) <br> \n",
    "<b>Date:</b> Jan 2025 <br>\n",
    "<br> <br> \n",
    "\n",
    "TL;DR <br>\n",
    "GAN (Generative Adversarial Network) to generate 64x64 cat faces images (based on this [dataset](https://www.kaggle.com/datasets/spandan2/cats-faces-64x64-for-generative-models/code)) using TensorFlow and Keras. The  architecture includes a generator to synthesize images from noise and a discriminator to classify real versus generated images, with training controlled by hyperparameters like batch size, noise dimension and epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Tuple, List, Union\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 256\n",
    "NOISE_DIM: int = 100\n",
    "EPOCHS: int = 1000\n",
    "BUFFER_SIZE: int = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Preprocess an image by resizing, reordering channels if necessary, and normalizing.\n",
    "\n",
    "    Args:\n",
    "        image (tf.Tensor): Input image tensor.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Preprocessed image tensor.\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, [64, 64])\n",
    "    channels = tf.shape(image)[-1]\n",
    "    if channels > 3:\n",
    "        image = image[:, :, :3]  \n",
    "    \n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image\n",
    "\n",
    "def load_dataset(path: str) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the dataset directory.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Preprocessed dataset ready for training.\n",
    "    \"\"\"\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        label_mode=None,\n",
    "        image_size=(64, 64),\n",
    "        batch_size=None\n",
    "    )\n",
    "    dataset = dataset.filter(lambda x: tf.shape(x)[0] == 64 and tf.shape(x)[1] == 64 and tf.shape(x)[-1] == 3)\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset(\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch in dataset.take(1):  \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(min(6, image_batch.shape[0])):  \n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        img = image_batch[i].numpy() \n",
    "        img = ((img * 127.5) + 127.5).astype(np.uint8) \n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = []\n",
    "for image in dataset.unbatch():\n",
    "    pixel_values.append(image.numpy().flatten())\n",
    "pixel_values = tf.concat(pixel_values, axis=0)\n",
    "\n",
    "print(f\"Mean pixel value: {tf.reduce_mean(pixel_values).numpy():.4f}\")\n",
    "print(f\"Std dev pixel value: {tf.math.reduce_std(pixel_values).numpy():.4f}\")\n",
    "print(f\"Pixel value range: [{tf.reduce_min(pixel_values).numpy()}, {tf.reduce_max(pixel_values).numpy()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = {0: [], 1: [], 2: []}\n",
    "\n",
    "for image in dataset.unbatch().take(100): \n",
    "    for i in range(3):\n",
    "        channel_data[i].extend(image[:, :, i].numpy().flatten())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, channel in channel_data.items():\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.hist(channel, bins=50, alpha=0.7, label=f'Channel {i+1}')\n",
    "    plt.title(f'Pixel Intensity Distribution - Channel {i+1}')\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Generator model for the GAN.\n",
    "    Generates images from random noise vectors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            layers.Dense(4*4*512, use_bias=False, input_shape=(100,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "\n",
    "            layers.Reshape((4, 4, 512)),\n",
    "\n",
    "            layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "\n",
    "            layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "\n",
    "            layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "\n",
    "            layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the generator.\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input noise vector of shape (batch_size, noise_dim).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Generated images of shape (batch_size, 64, 64, 3).\n",
    "        \"\"\"\n",
    "        return self.model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Discriminator model for the GAN.\n",
    "    Classifies images as real or fake.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[64, 64, 3]),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the discriminator.\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input images of shape (batch_size, 64, 64, 3).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Classification logits for each image.\n",
    "        \"\"\"\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output: tf.Tensor, fake_output: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the discriminator loss.\n",
    "\n",
    "    Args:\n",
    "        real_output (tf.Tensor): Discriminator predictions on real images.\n",
    "        fake_output (tf.Tensor): Discriminator predictions on fake images.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Total discriminator loss.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the generator loss.\n",
    "\n",
    "    Args:\n",
    "        fake_output (tf.Tensor): Discriminator predictions on generated images.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Generator loss.\n",
    "    \"\"\"\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(\n",
    "    model: tf.keras.Model, \n",
    "    epoch: int, \n",
    "    test_input: tf.Tensor, \n",
    "    save: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate and optionally save images using the generator model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained generator model.\n",
    "        epoch (int): The current training epoch (used for saving images with the epoch number).\n",
    "        test_input (tf.Tensor): Input tensor (e.g., random noise) to the generator for image generation.\n",
    "        save (bool): If True, saves the generated images to disk with a filename indicating the epoch.\n",
    "    \"\"\"\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow((predictions[i] + 1) / 2.0) \n",
    "        plt.axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'generated_cats/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform a single training step for the generator and discriminator.\n",
    "\n",
    "    Args:\n",
    "        images (tf.Tensor): Batch of real images.\n",
    "\n",
    "    Returns:\n",
    "        tuple[tf.Tensor, tf.Tensor]: Generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "def train(dataset: tf.data.Dataset, epochs: int) -> Tuple[List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Train the GAN for a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): Preprocessed dataset for training.\n",
    "        epochs (int): Number of training epochs.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float]]: Generator and discriminator losses over all epochs.\n",
    "    \"\"\"\n",
    "    losses_gen, losses_disc = [], [] \n",
    "    noise = tf.random.normal([16, NOISE_DIM])\n",
    "    for epoch in range(epochs):\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for image_batch in dataset: \n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            epoch_gen_loss.append(gen_loss.numpy())\n",
    "            epoch_disc_loss.append(disc_loss.numpy())\n",
    "\n",
    "        avg_gen_loss = sum(epoch_gen_loss) / len(epoch_gen_loss)\n",
    "        avg_disc_loss = sum(epoch_disc_loss) / len(epoch_disc_loss)\n",
    "\n",
    "        losses_gen.append(avg_gen_loss)\n",
    "        losses_disc.append(avg_disc_loss)\n",
    "\n",
    "        generate_and_save_images(generator, epoch + 1, noise, True)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}\")\n",
    "\n",
    "    return losses_gen, losses_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_gen, losses_disc = train(dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_generated_images(generator: tf.keras.Model, num_images: int = 16):\n",
    "    \"\"\"\n",
    "    Generate and visualize images from the GAN generator.\n",
    "\n",
    "    Args:\n",
    "        generator (tf.keras.Model): The generator model.\n",
    "        num_images (int): Number of images to generate and display.\n",
    "    \"\"\"\n",
    "    noise = tf.random.normal([num_images, NOISE_DIM])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2.0\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i])\n",
    "        axes[i].axis('off')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_generated_images(generator, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(generator_losses: List[float], discriminator_losses: List[float]) -> None:\n",
    "    \"\"\"\n",
    "    Plot the generator and discriminator losses over epochs.\n",
    "\n",
    "    Args:\n",
    "        generator_losses (List[float]): List of generator loss values recorded during training.\n",
    "        discriminator_losses (List[float]): List of discriminator loss values recorded during training.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(generator_losses, label=\"Generator Loss\")\n",
    "    plt.plot(discriminator_losses, label=\"Discriminator Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Losses during GAN Training\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(losses_gen, losses_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_interpolation(generator: tf.keras.Model,steps: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Visualize latent space interpolation by generating smooth transitions between images.\n",
    "\n",
    "    Args:\n",
    "        generator (tf.keras.Model): The generator model.\n",
    "        noise_dim (int): The dimensionality of the noise vector input to the generator.\n",
    "        steps (int): Number of interpolated steps between two random noise vectors.\n",
    "    \"\"\"\n",
    "    noise_start = tf.random.normal([1, NOISE_DIM])\n",
    "    noise_end = tf.random.normal([1, NOISE_DIM])\n",
    "    interpolated_noise = [\n",
    "        noise_start + (t / (steps - 1)) * (noise_end - noise_start) for t in range(steps)\n",
    "    ]\n",
    "    interpolated_noise = tf.concat(interpolated_noise, axis=0)\n",
    "\n",
    "    generated_images = generator(interpolated_noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2.0  \n",
    "\n",
    "    fig, axes = plt.subplots(1, steps, figsize=(20, 5))\n",
    "    for i, img in enumerate(generated_images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_latent_interpolation(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_diversity(generator: tf.keras.Model, num_images: int = 16) -> None:\n",
    "    \"\"\"\n",
    "    Visualize the diversity of generated images by sampling multiple random noise vectors.\n",
    "\n",
    "    Args:\n",
    "        generator (tf.keras.Model): The generator model.\n",
    "        num_images (int): Number of images to generate and display.\n",
    "        noise_dim (int): Dimensionality of the input noise vector.\n",
    "    \"\"\"\n",
    "    noise = tf.random.normal([num_images, NOISE_DIM])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2.0\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i])\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_image_diversity(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif_from_images(image_folder: str, gif_name: str, duration: float = 0.3) -> None:\n",
    "    \"\"\"\n",
    "    Generate a GIF from saved images in a specified folder.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): Path to the folder containing the images.\n",
    "        gif_name (str): Output name for the GIF file.\n",
    "        duration (float): Duration for each frame in the GIF (in seconds).\n",
    "    \"\"\"\n",
    "    images = sorted(\n",
    "        [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.png')]\n",
    "    )\n",
    "    \n",
    "    if not images:\n",
    "        print(f\"No images found in folder: {image_folder}\")\n",
    "        return\n",
    "    \n",
    "    frames = [imageio.imread(image) for image in images]\n",
    "    gif_path = os.path.join(image_folder, gif_name)\n",
    "    imageio.mimsave(gif_path, frames, duration=duration)\n",
    "\n",
    "create_gif_from_images('generated_cats', 'cats_gan.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
